import os, uuid, json
from typing import List, Optional
from fastapi import FastAPI, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from sse_starlette.sse import EventSourceResponse
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from .retrieval import HybridCorpus
from .graph_index import GraphIndex
from .agents import MultiAgent
from .agentic_rag import AgenticRAGSystem
from .storage import append_trace, read_traces
from .langx import run_extraction, stream_extraction
from .profiles import PROFILES

app = FastAPI(title="MultiAgent-RAG Pro")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
origins = [
    "https://vasilykolbenev.github.io",  # –í–∞—à GitHub Pages
    "http://localhost:8001",           # –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    "http://localhost",                # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    "null",                            # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (file://)
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

corpus = HybridCorpus()
graph = GraphIndex()
agent = MultiAgent(corpus, graph)
agentic_system = AgenticRAGSystem(corpus, graph)

@app.get("/health")
def health(): return {"ok": True, "model": os.getenv("LLM_MODEL","gpt-5-mini")}

@app.get("/profiles")
def profiles(): return PROFILES

@app.get("/traces")
def traces(): return read_traces()

@app.post("/ingest/text")
async def ingest_text(text: str = Form(...), doc_id: Optional[str] = Form(None)):
    """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç ID, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω."""
    try:
        if not doc_id:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π doc_id –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö—ç—à–∞ —Ç–µ–∫—Å—Ç–∞
            import hashlib
            doc_id = f"doc_{hashlib.md5(text[:100].encode()).hexdigest()[:8]}"
            
        corpus.ingest_text(doc_id, text)
        append_trace({"type":"ingest", "doc_id":doc_id, "len":len(text)})
        return {"ok": True, "doc_id": doc_id}
    except Exception as e:
        print(f"ERROR in /ingest/text: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"message": "Internal Server Error during ingestion"})

@app.post("/ingest/files")
async def ingest_files(files: List[UploadFile] = File(...)):
    saved = []
    base = os.environ.get("DOCS_DIR", "data/docs"); os.makedirs(base, exist_ok=True)
    for f in files:
        fp = os.path.join(base, f.filename)
        with open(fp, "wb") as out: out.write(await f.read())
        saved.append(f.filename)
    corpus.load_folder(base)
    append_trace({"type":"ingest_files", "files":saved})
    return {"ok": True, "files": saved, "count": len(saved)}

@app.post("/ingest/folder")
async def ingest_folder(path: str = Form(...)):
    corpus.ingest_folder(path)
    append_trace({"type":"ingest_folder", "path": path})
    return {"ok": True}

@app.get("/search")
def search(q: str, k: int = 5, entities: Optional[str] = None):
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å—É—â–Ω–æ—Å—Ç—è–º –∑–¥–µ—Å—å –±–æ–ª—å—à–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é,
    # —Ç–∞–∫ –∫–∞–∫ –ø–æ–∏—Å–∫ —Ç–µ–ø–µ—Ä—å –≥–∏–±—Ä–∏–¥–Ω—ã–π. –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –±—É–¥—É—â–µ–º.
    res = corpus.search(q, k=k)
    return JSONResponse(res)

@app.get("/ask")
async def ask(q: str, k: int = 5, entities: Optional[str] = None):
    ents = [x.strip() for x in entities.split(",")] if entities else None
    append_trace({"type":"query", "q": q, "entities": ents})
    res = await agent.run(q, k=k, entities_filter=ents)
    append_trace({"type":"result", "q": q, "answer": res.get("answer","")[:200], "citations": res.get("citations", [])})
    return JSONResponse(res)

@app.get("/ask/stream")
async def ask_stream(q: str, k: int = 5, entities: Optional[str] = None):
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ RAG-–æ—Ç–≤–µ—Ç–∞ (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π MultiAgent)."""
    ents = [x.strip() for x in entities.split(",")] if entities else None
    
    async def event_generator():
        try:
            async for event in agent.stream(q, k=k, entities_filter=ents):
                yield {
                    "event": "message",
                    "data": json.dumps(event)
                }
        except Exception as e:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ —Å –æ—à–∏–±–∫–æ–π –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥
            error_event = {"type": "error", "data": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"}
            yield {
                "event": "message",
                "data": json.dumps(error_event)
            }
            # –¢–∞–∫–∂–µ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
            print(f"Error during stream: {e}")

    return EventSourceResponse(
        event_generator(),
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )

@app.get("/ask/agentic")
async def ask_agentic(q: str, max_iterations: int = 5, confidence_threshold: float = 0.7):
    """üöÄ –ù–æ–≤—ã–π Agentic RAG —ç–Ω–¥–ø–æ–∏–Ω—Ç - —É–º–Ω–∞—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤."""
    try:
        result = await agentic_system.process_query(
            query=q, 
            max_iterations=max_iterations,
            confidence_threshold=confidence_threshold
        )
        append_trace({"type": "agentic_query", "q": q, "iterations": result.get("agentic_metadata", {}).get("iterations_used", 0)})
        return JSONResponse(result)
    except Exception as e:
        print(f"ERROR in /ask/agentic: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"message": f"Agentic RAG error: {e}"})

@app.get("/ask/agentic/stream")
async def ask_agentic_stream(q: str, max_iterations: int = 5):
    """üöÄ –ü–æ—Ç–æ–∫–æ–≤—ã–π Agentic RAG - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–∞–º–∏."""
    
    async def agentic_event_generator():
        try:
            async for event in agentic_system.stream_query(q, max_iterations=max_iterations):
                yield {
                    "event": "message",
                    "data": json.dumps(event, ensure_ascii=False)
                }
        except Exception as e:
            error_event = {"type": "agentic_error", "data": f"Agentic RAG error: {e}"}
            yield {
                "event": "message", 
                "data": json.dumps(error_event)
            }
            print(f"Agentic RAG stream error: {e}")

    return EventSourceResponse(
        agentic_event_generator(),
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )

@app.get("/documents")
def get_documents():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    return JSONResponse(corpus.list_docs())

@app.delete("/documents/{doc_id}")
def delete_document(doc_id: str):
    """–£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ –µ–≥–æ ID."""
    success = corpus.delete_doc(doc_id)
    if success:
        return JSONResponse({"status": "ok", "message": f"Document {doc_id} deleted."})
    else:
        return JSONResponse({"status": "error", "message": f"Document {doc_id} not found."}, status_code=404)

@app.post("/langextract/text")
async def langextract_text(task_prompt: str = Form(None), text: str = Form(...), doc_id: str = Form("extracted_doc")):
    try:
        out = run_extraction(text, prompt=task_prompt)
        graph.update_from_items(doc_id, out["items"])
        return JSONResponse(out)
    except Exception as e:
        print(f"ERROR in /langextract/text: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"message": "Internal Server Error during extraction"})

@app.get("/langextract/stream_text")
async def langextract_stream_text(text: str, task_prompt: Optional[str] = None, doc_id: str = "extracted_doc"):
    def gen():
        last = None
        for ev in stream_extraction(text, prompt=task_prompt):
            last = ev
            yield {"event": "message", "data": json.dumps(ev, ensure_ascii=False)}
        if last and isinstance(last, dict) and "result" in last:
            graph.update_from_items(doc_id, last["result"].get("items", []))
    return EventSourceResponse(gen())

@app.get("/extracts/{job_id}/viz.html")
async def get_viz(job_id: str):
    fp = os.path.join("data","extracts",job_id,"viz.html")
    if not os.path.exists(fp): return JSONResponse({"error":"not found"}, status_code=404)
    return FileResponse(fp, media_type="text/html")
