import os, uuid, json
from typing import List, Optional
from fastapi import FastAPI, UploadFile, File, Form, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
from sse_starlette.sse import EventSourceResponse
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from retrieval import HybridCorpus, Document, EmbeddedDocument, update_document_in_corpus, get_corpus_stats, clear_corpus
from agents import MultiAgent
from llm import LLM
from graph_index import GraphIndex
from agentic_rag import AgenticRAGSystem
from storage import append_trace, read_traces
from langx import run_extraction, stream_extraction
from profiles import PROFILES

app = FastAPI(title="MultiAgent-RAG Pro")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CORS –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
origins = [
    "https://vasilykolbenev.github.io",  # –í–∞—à GitHub Pages
    "http://localhost:8001",           # –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–æ–≤
    "http://localhost",                # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
    "null",                            # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (file://)
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "DELETE", "OPTIONS"],
    allow_headers=["*"],
)

corpus = HybridCorpus()
graph = GraphIndex()
agent = MultiAgent(corpus, graph)
agentic_system = AgenticRAGSystem(corpus, graph)

@app.get("/health")
def health(): return {"ok": True, "model": os.getenv("LLM_MODEL","gpt-5-mini")}

@app.get("/profiles")
def profiles(): return PROFILES

@app.get("/traces")
def traces(): return read_traces()

@app.post("/ingest/text")
async def ingest_text(text: str = Form(...), doc_id: Optional[str] = Form(None)):
    """–ü—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–µ–∫—Å—Ç, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç ID, –µ—Å–ª–∏ –æ–Ω –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω."""
    try:
        if not doc_id:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π doc_id –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö—ç—à–∞ —Ç–µ–∫—Å—Ç–∞
            import hashlib
            doc_id = f"doc_{hashlib.md5(text[:100].encode()).hexdigest()[:8]}"
            
        corpus.ingest_text(doc_id, text)
        append_trace({"type":"ingest", "doc_id":doc_id, "len":len(text)})
        return {"ok": True, "doc_id": doc_id}
    except Exception as e:
        print(f"ERROR in /ingest/text: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"message": "Internal Server Error during ingestion"})

@app.post("/ingest/files")
async def ingest_files(files: List[UploadFile] = File(...)):
    saved = []
    base = os.environ.get("DOCS_DIR", "data/docs"); os.makedirs(base, exist_ok=True)
    for f in files:
        fp = os.path.join(base, f.filename)
        with open(fp, "wb") as out: out.write(await f.read())
        saved.append(f.filename)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ ingest_text
    for filename in saved:
        filepath = os.path.join(base, filename)
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                doc_id = f"file_{filename}_{uuid.uuid4().hex[:8]}"
                corpus.ingest_text(doc_id, content)
        except Exception as e:
            print(f"Error loading file {filename}: {e}")
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
            try:
                with open(filepath, 'r', encoding='cp1251') as f:
                    content = f.read()
                    doc_id = f"file_{filename}_{uuid.uuid4().hex[:8]}"
                    corpus.ingest_text(doc_id, content)
            except Exception as e2:
                print(f"Error loading file {filename} with cp1251: {e2}")
                continue
    
    append_trace({"type":"ingest_files", "files":saved})
    return {"ok": True, "files": saved, "count": len(saved)}

@app.post("/ingest")
async def ingest_unified(files: List[UploadFile] = File(None), text: str = Form(None), doc_id: Optional[str] = Form(None)):
    """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞"""
    results = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if files:
        base = os.environ.get("DOCS_DIR", "data/docs"); os.makedirs(base, exist_ok=True)
        for f in files:
            fp = os.path.join(base, f.filename)
            with open(fp, "wb") as out: 
                out.write(await f.read())
            results.append({"type": "file", "filename": f.filename})
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ ingest_text
        for f in files:
            try:
                filepath = os.path.join(base, f.filename)
                with open(filepath, 'r', encoding='utf-8') as file_content:
                    content = file_content.read()
                    doc_id = f"file_{f.filename}_{uuid.uuid4().hex[:8]}"
                    corpus.ingest_text(doc_id, content)
            except Exception as e:
                print(f"Error loading file {f.filename}: {e}")
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
                try:
                    with open(filepath, 'r', encoding='cp1251') as file_content:
                        content = file_content.read()
                        doc_id = f"file_{f.filename}_{uuid.uuid4().hex[:8]}"
                        corpus.ingest_text(doc_id, content)
                except Exception as e2:
                    print(f"Error loading file {f.filename} with cp1251: {e2}")
                    continue
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
    if text and text.strip():
        if not doc_id:
            doc_id = f"text_{uuid.uuid4().hex[:8]}"
        
        try:
            import hashlib
            corpus.ingest_text(doc_id, text)
            results.append({"type": "text", "doc_id": doc_id})
        except Exception as e:
            import traceback
            print(f"Error during text ingestion: {e}")
            traceback.print_exc()
            return JSONResponse(status_code=500, content={"error": str(e)})
    
    if not results:
        return JSONResponse(status_code=400, content={"error": "No files or text provided"})
    
    append_trace({"type":"ingest_unified", "results": results})
    return {"ok": True, "results": results, "count": len(results)}

@app.post("/ingest/folder")
async def ingest_folder(path: str = Form(...)):
    corpus.ingest_folder(path)
    append_trace({"type":"ingest_folder", "path": path})
    return {"ok": True}

@app.get("/search")
def search(q: str, k: int = 5, entities: Optional[str] = None):
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Å—É—â–Ω–æ—Å—Ç—è–º –∑–¥–µ—Å—å –±–æ–ª—å—à–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é,
    # —Ç–∞–∫ –∫–∞–∫ –ø–æ–∏—Å–∫ —Ç–µ–ø–µ—Ä—å –≥–∏–±—Ä–∏–¥–Ω—ã–π. –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –±—É–¥—É—â–µ–º.
    res = corpus.search(q, k=k)
    return JSONResponse(res)

@app.get("/ask")
async def ask(q: str, k: int = 5, entities: Optional[str] = None):
    ents = [x.strip() for x in entities.split(",")] if entities else None
    append_trace({"type":"query", "q": q, "entities": ents})
    res = await agent.run(q, k=k, entities_filter=ents)
    append_trace({"type":"result", "q": q, "answer": res.get("answer","")[:200], "citations": res.get("citations", [])})
    return JSONResponse(res)

@app.get("/ask/stream")
async def ask_stream(q: str, k: int = 5, entities: Optional[str] = None):
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏ RAG-–æ—Ç–≤–µ—Ç–∞ (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π MultiAgent)."""
    ents = [x.strip() for x in entities.split(",")] if entities else None
    
    async def event_generator():
        try:
            async for event in agent.stream(q, k=k, entities_filter=ents):
                yield {
                    "event": "message",
                    "data": json.dumps(event)
                }
        except Exception as e:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ —Å –æ—à–∏–±–∫–æ–π –Ω–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥
            error_event = {"type": "error", "data": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"}
            yield {
                "event": "message",
                "data": json.dumps(error_event)
            }
            # –¢–∞–∫–∂–µ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
            print(f"Error during stream: {e}")

    return EventSourceResponse(
        event_generator(),
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )

@app.get("/ask/agentic")
async def ask_agentic(q: str, max_iterations: int = 5, confidence_threshold: float = 0.7):
    """üöÄ –ù–æ–≤—ã–π Agentic RAG —ç–Ω–¥–ø–æ–∏–Ω—Ç - —É–º–Ω–∞—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤."""
    try:
        result = await agentic_system.process_query(
            query=q, 
            max_iterations=max_iterations,
            confidence_threshold=confidence_threshold
        )
        append_trace({"type": "agentic_query", "q": q, "iterations": result.get("agentic_metadata", {}).get("iterations_used", 0)})
        return JSONResponse(result)
    except Exception as e:
        print(f"ERROR in /ask/agentic: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"message": f"Agentic RAG error: {e}"})

@app.get("/ask/agentic/stream")
async def ask_agentic_stream(q: str, max_iterations: int = 5):
    """üöÄ –ü–æ—Ç–æ–∫–æ–≤—ã–π Agentic RAG - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –∞–≥–µ–Ω—Ç–∞–º–∏."""
    
    async def agentic_event_generator():
        try:
            async for event in agentic_system.stream_query(q, max_iterations=max_iterations):
                yield {
                    "event": "message",
                    "data": json.dumps(event, ensure_ascii=False)
                }
        except Exception as e:
            error_event = {"type": "agentic_error", "data": f"Agentic RAG error: {e}"}
            yield {
                "event": "message", 
                "data": json.dumps(error_event)
            }
            print(f"Agentic RAG stream error: {e}")

    return EventSourceResponse(
        agentic_event_generator(),
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )

@app.get("/documents")
def get_documents():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    return JSONResponse(corpus.list_docs())

@app.get("/analytics/entities")
def get_entities_analytics():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ —Å—É—â–Ω–æ—Å—Ç—è–º –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π."""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –≥—Ä–∞—Ñ–∞
        all_entities = graph.get_all_entities_with_stats()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_entities = len(all_entities)
        total_documents = len(corpus.list_docs())
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º
        entity_types = {}
        entity_cloud = []
        
        for entity in all_entities:
            entity_type = entity.get('class', 'unknown')
            entity_text = entity.get('text', '')
            entity_count = entity.get('doc_count', 1)
            
            if entity_type not in entity_types:
                entity_types[entity_type] = 0
            entity_types[entity_type] += entity_count
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±–ª–∞–∫–æ —Å –≤–µ—Å–æ–º
            entity_cloud.append({
                'text': entity_text,
                'type': entity_type,
                'count': entity_count,
                'weight': min(entity_count * 10, 100)  # –í–µ—Å –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –≤ –æ–±–ª–∞–∫–µ
            })
        
        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        top_entity_type = max(entity_types.items(), key=lambda x: x[1])[0] if entity_types else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–ª–∞–∫–æ –ø–æ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
        entity_cloud.sort(key=lambda x: x['count'], reverse=True)
        entity_cloud = entity_cloud[:50]  # –¢–æ–ø-50 —Å—É—â–Ω–æ—Å—Ç–µ–π
        
        return JSONResponse({
            'total_entities': total_entities,
            'total_documents': total_documents,
            'top_entity_type': top_entity_type,
            'entity_types': entity_types,
            'entity_cloud': entity_cloud
        })
        
    except Exception as e:
        print(f"ERROR in /analytics/entities: {e}")
        return JSONResponse({
            'total_entities': 0,
            'total_documents': len(corpus.list_docs()) if corpus else 0,
            'top_entity_type': '–û—à–∏–±–∫–∞',
            'entity_types': {},
            'entity_cloud': []
        })

@app.delete("/documents/{doc_id}")
def delete_document(doc_id: str):
    """–£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ –µ–≥–æ ID."""
    success = corpus.delete_doc(doc_id)
    if success:
        return JSONResponse({"status": "ok", "message": f"Document {doc_id} deleted."})
    else:
        return JSONResponse({"status": "error", "message": f"Document {doc_id} not found."}, status_code=404)

@app.post("/langextract/text")
async def langextract_text(task_prompt: str = Form(None), text: str = Form(...), doc_id: str = Form("extracted_doc")):
    try:
        out = run_extraction(text, prompt=task_prompt)
        graph.update_from_items(doc_id, out["items"])
        return JSONResponse(out)
    except Exception as e:
        print(f"ERROR in /langextract/text: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"message": "Internal Server Error during extraction"})

@app.post("/langextract")
async def langextract_unified(request_data: dict = Body(...)):
    """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è LangExtract —Å JSON –≤—Ö–æ–¥–æ–º"""
    try:
        text = request_data.get('text', '')
        task_prompt = request_data.get('task_prompt')
        doc_id = request_data.get('doc_id', 'extracted_doc')
        
        if not text.strip():
            return JSONResponse(status_code=400, content={"message": "Text is required", "success": False})
        
        out = run_extraction(text, prompt=task_prompt)
        graph.update_from_items(doc_id, out["items"])
        return JSONResponse(out)
    except Exception as e:
        print(f"ERROR in /langextract: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(status_code=500, content={"message": "Internal Server Error during extraction", "error": str(e), "success": False})

@app.get("/langextract/stream_text")
async def langextract_stream_text(text: str, task_prompt: Optional[str] = None, doc_id: str = "extracted_doc"):
    def gen():
        last = None
        for ev in stream_extraction(text, prompt=task_prompt):
            last = ev
            yield {"event": "message", "data": json.dumps(ev, ensure_ascii=False)}
        if last and isinstance(last, dict) and "result" in last:
            graph.update_from_items(doc_id, last["result"].get("items", []))
    return EventSourceResponse(gen())

@app.get("/extracts/{job_id}/viz.html")
async def get_viz(job_id: str):
    fp = os.path.join("data","extracts",job_id,"viz.html")
    if not os.path.exists(fp): return JSONResponse({"error":"not found"}, status_code=404)
    return FileResponse(fp, media_type="text/html")

@app.post("/api/extract-pdf-text")
async def extract_pdf_text(file: UploadFile = File(...)):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Ñ–∞–π–ª–∞"""
    try:
        if not file.filename.lower().endswith('.pdf'):
            return JSONResponse({"error": "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ PDF —Ñ–∞–π–ª—ã"}, status_code=400)
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        content = await file.read()
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pypdf –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
        try:
            from pypdf import PdfReader
            import io
            
            pdf_file = io.BytesIO(content)
            pdf_reader = PdfReader(pdf_file)
            
            text = ""
            for page_num, page in enumerate(pdf_reader.pages, 1):
                page_text = page.extract_text()
                if page_text.strip():
                    text += f"\n--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} ---\n{page_text}\n"
            
            if not text.strip():
                return JSONResponse({"error": "PDF —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω"}, status_code=400)
            
            return JSONResponse({"text": text.strip()})
            
        except ImportError:
            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º pdfplumber –µ—Å–ª–∏ PyPDF2 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            try:
                import pdfplumber
                
                text = ""
                with pdfplumber.open(io.BytesIO(content)) as pdf:
                    for page_num, page in enumerate(pdf.pages, 1):
                        page_text = page.extract_text()
                        if page_text:
                            text += f"\n--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} ---\n{page_text}\n"
                
                if not text.strip():
                    return JSONResponse({"error": "PDF —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞"}, status_code=400)
                
                return JSONResponse({"text": text.strip()})
                
            except ImportError:
                return JSONResponse({
                    "error": "–î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ PyPDF2 –∏–ª–∏ pdfplumber. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é."
                }, status_code=500)
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {e}")
        return JSONResponse({"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {str(e)}"}, status_code=500)

@app.post("/api/extract-text")
async def extract_text(file: UploadFile = File(...)):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤"""
    try:
        filename = file.filename.lower()
        content = await file.read()
        
        # PDF —Ñ–∞–π–ª—ã
        if filename.endswith('.pdf'):
            try:
                from pypdf import PdfReader
                import io
                
                pdf_file = io.BytesIO(content)
                pdf_reader = PdfReader(pdf_file)
                
                text = ""
                for page_num, page in enumerate(pdf_reader.pages, 1):
                    page_text = page.extract_text()
                    if page_text.strip():
                        text += f"\n--- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} ---\n{page_text}\n"
                
                return JSONResponse({"text": text.strip() or "PDF —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞"})
                
            except Exception as e:
                return JSONResponse({"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {str(e)}"}, status_code=500)
        
        # DOCX —Ñ–∞–π–ª—ã
        elif filename.endswith('.docx'):
            try:
                import io
                from docx import Document
                
                print(f"Processing DOCX file: {filename}, size: {len(content)} bytes")
                doc_file = io.BytesIO(content)
                doc = Document(doc_file)
                
                text = ""
                for paragraph in doc.paragraphs:
                    if paragraph.text and paragraph.text.strip():
                        # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
                        para_text = paragraph.text.strip()
                        text += para_text + "\n"
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            if cell.text and cell.text.strip():
                                cell_text = cell.text.strip()
                                text += cell_text + "\n"
                
                # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ç–µ–∫—Å—Ç –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–µ
                if text.strip():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
                    try:
                        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∞–∫–æ–∑—è–±—Ä—ã, –ø—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å
                        if 'ÔøΩ' in text or any(ord(c) > 65535 for c in text):
                            print("Detected encoding issues in DOCX, attempting to fix...")
                            # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å
                            text = text.encode('utf-8', errors='ignore').decode('utf-8')
                    except Exception as encoding_error:
                        print(f"Encoding fix failed: {encoding_error}")
                
                return JSONResponse({
                    "text": text.strip() or "DOCX —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞",
                    "format": "docx"
                })
                
            except ImportError:
                # Fallback: –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å docx2txt –µ—Å–ª–∏ python-docx –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
                try:
                    import docx2txt
                    import io
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è docx2txt
                    import tempfile
                    import os
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp_file:
                        tmp_file.write(content)
                        tmp_file_path = tmp_file.name
                    
                    try:
                        text = docx2txt.process(tmp_file_path)
                        os.unlink(tmp_file_path)  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                        
                        return JSONResponse({
                            "text": text.strip() or "DOCX —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞",
                            "format": "docx-fallback"
                        })
                    except Exception as docx2txt_error:
                        os.unlink(tmp_file_path)  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                        raise docx2txt_error
                        
                except ImportError:
                    return JSONResponse({
                        "error": "–î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ python-docx –∏–ª–∏ docx2txt"
                    }, status_code=500)
            except Exception as e:
                import traceback
                error_details = traceback.format_exc()
                print(f"DOCX processing error: {e}")
                print(f"Full traceback: {error_details}")
                return JSONResponse({
                    "error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ DOCX: {str(e)}",
                    "details": str(e)
                }, status_code=500)
        
        # –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        elif filename.endswith(('.txt', '.md', '.rtf', '.csv')):
            try:
                import chardet
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É
                detected = chardet.detect(content)
                encoding = detected.get('encoding', 'utf-8')
                confidence = detected.get('confidence', 0)
                
                print(f"Detected encoding: {encoding} (confidence: {confidence})")
                
                # –ü—Ä–æ–±—É–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
                try:
                    text = content.decode(encoding)
                except UnicodeDecodeError:
                    # Fallback –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞
                    fallback_encodings = ['utf-8', 'windows-1251', 'cp1251', 'koi8-r']
                    text = None
                    
                    for enc in fallback_encodings:
                        try:
                            text = content.decode(enc)
                            print(f"Successfully decoded with fallback encoding: {enc}")
                            break
                        except UnicodeDecodeError:
                            continue
                    
                    if text is None:
                        text = content.decode('utf-8', errors='replace')
                        print("Used UTF-8 with error replacement")
                
                return JSONResponse({"text": text, "encoding": encoding, "confidence": confidence})
                
            except ImportError:
                # –ï—Å–ª–∏ chardet –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ fallback'–∏
                fallback_encodings = ['utf-8', 'windows-1251', 'cp1251']
                for encoding in fallback_encodings:
                    try:
                        text = content.decode(encoding)
                        return JSONResponse({"text": text, "encoding": encoding})
                    except UnicodeDecodeError:
                        continue
                
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback
                text = content.decode('utf-8', errors='replace')
                return JSONResponse({"text": text, "encoding": "utf-8-replace"})
            
            except Exception as e:
                return JSONResponse({"error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞: {str(e)}"}, status_code=500)
        
        else:
            return JSONResponse({
                "error": f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {filename}"
            }, status_code=400)
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {e}")
        print(f"Full traceback: {error_details}")
        return JSONResponse({
            "error": f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {str(e)}",
            "type": "general_error",
            "filename": filename
        }, status_code=500)