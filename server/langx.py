import os, uuid, json, textwrap, time
from typing import Any, Dict, List, Optional, Generator

# –î–µ–ª–∞–µ–º langextract –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º, —á—Ç–æ–±—ã –¥–µ–ø–ª–æ–π –Ω–∞ Railway –Ω–µ –ø–∞–¥–∞–ª –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –ø–∞–∫–µ—Ç–∞
try:
    import langextract as lx
except Exception as _e:
    lx = None
    print("[langx] LangExtract is not available, extraction endpoints will be limited.")

MODEL_ID = os.environ.get("LX_MODEL_ID", "gpt-4o-mini")  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—É—é –º–æ–¥–µ–ª—å

DEFAULT_PROMPT = textwrap.dedent("""–ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (organization, person, date, money) –∏ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –º–µ–∂–¥—É –Ω–∏–º–∏.
–°—Ç—Ä–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–π —Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π). –í–µ—Ä–Ω–∏ –∞—Ç—Ä–∏–±—É—Ç—ã: type, value, optional_attrs.
""")

def _examples_default():
    return [lx.data.ExampleData(
        text="–ö–æ–º–ø–∞–Ω–∏—è ACME –≤—ã—Ä—É—á–∏–ª–∞ $12.4M –≤–æ 2 –∫–≤–∞—Ä—Ç–∞–ª–µ 2025 –≥–æ–¥–∞.",
        extractions=[
            lx.data.Extraction(extraction_class="organization", extraction_text="ACME"),
            lx.data.Extraction(extraction_class="money", extraction_text="$12.4M", attributes={"period":"Q2 2025"}),
        ],
    )]

def run_extraction(text_or_url: str, prompt: Optional[str]=None, examples: Optional[List[Dict[str, Any]]]=None) -> Dict[str, Any]:
    if lx is None:
        # LangExtract –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —Ç–∏—Ö–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return {"job_id": "disabled", "items": []}
    prompt = prompt or DEFAULT_PROMPT
    ex = _examples_default()
    if examples:
        ex = [lx.data.ExampleData(
                text=e.get("text",""),
                extractions=[lx.data.Extraction(extraction_class=it.get("class","entity"), extraction_text=it.get("text",""), attributes=it.get("attributes",{}))
                             for it in e.get("extractions",[])]
             ) for e in examples]

    # --- DEBUG LANGEXTRACT PARAMS ---
    from . import config
    # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—É—é –º–æ–¥–µ–ª—å (Railway –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é)
    lx_model_id = "gpt-4o-mini"  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ, —Ç–∞–∫ –∫–∞–∫ Railway –∏–º–µ–µ—Ç —Å—Ç–∞—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ Variables
    api_key = config.OPENAI_API_KEY
    print("="*50)
    print("üîç DEBUG: LangExtract Parameters")
    print(f"  - Model ID: {lx_model_id}")
    print(f"  - API Key Set: {'Yes' if api_key else 'No'}")
    print("="*50)
    # --- END DEBUG ---

    try:
        result = lx.extract(
            text_or_documents=text_or_url,
            prompt_description=prompt,
            examples=ex,
            model_id=lx_model_id,
            api_key=api_key,
            fence_output=True,
            use_schema_constraints=False,
        )
    except Exception as e:
        print("="*50)
        print("‚ùå CRITICAL: LangExtract failed with an exception!")
        print(f"   Error: {e}")
        import traceback
        traceback.print_exc()
        print("="*50)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å –≤–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å
        return {"job_id": "error", "items": []}
    
    job_id = uuid.uuid4().hex[:8]
    out_dir = os.path.join("data", "extracts", job_id); os.makedirs(out_dir, exist_ok=True)
    lx.io.save_annotated_documents([result], output_name="result.jsonl", output_dir=out_dir)
    html = lx.visualize(os.path.join(out_dir, "result.jsonl"))
    with open(os.path.join(out_dir, "viz.html"), "w", encoding="utf-8") as f:
        f.write(html.data if hasattr(html, 'data') else html)
    flat = []
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É LangExtract - result –º–æ–∂–µ—Ç –±—ã—Ç—å AnnotatedDocument
    if hasattr(result, 'documents'):
        # –°—Ç–∞—Ä–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
        for doc in result.documents:
            for ann in doc.annotations:
                flat.append({"class": ann.extraction_class, "text": ann.extraction_text, "attributes": ann.attributes or {}, "doc_char_start": ann.char_start, "doc_char_end": ann.char_end})
    elif hasattr(result, 'extractions'):
        # –ù–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ - result.extractions —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏–π
        for extraction in result.extractions:
            flat.append({
                "class": extraction.extraction_class, 
                "text": extraction.extraction_text, 
                "attributes": extraction.attributes or {}, 
                "doc_char_start": getattr(extraction, 'char_start', 0), 
                "doc_char_end": getattr(extraction, 'char_end', 0)
            })
        print(f"‚úÖ LangExtract —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ–∫ {len(flat)} —Å—É—â–Ω–æ—Å—Ç–µ–π!")
    elif hasattr(result, 'annotations'):
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ - result.annotations
        for ann in result.annotations:
            flat.append({"class": ann.extraction_class, "text": ann.extraction_text, "attributes": ann.attributes or {}, "doc_char_start": ann.char_start, "doc_char_end": ann.char_end})
    else:
        # –ï—Å–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        print(f"‚ö†Ô∏è Unknown LangExtract result structure: {type(result)}")
        print(f"Available attributes: {dir(result)}")
    
    return {"job_id": job_id, "items": flat}

def stream_extraction(text_or_url: str, prompt: Optional[str]=None) -> Generator[Dict[str, Any], None, None]:
    start = time.time()
    yield {"event":"start","t":0}
    time.sleep(0.2); yield {"event":"fetch","msg":"–ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç","t":time.time()-start}
    time.sleep(0.2); yield {"event":"analyze","msg":"LLM –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—É—â–Ω–æ—Å—Ç–∏","t":time.time()-start}
    res = run_extraction(text_or_url, prompt=prompt)
    time.sleep(0.2); yield {"event":"save","msg":"–°–æ—Ö—Ä–∞–Ω—è–µ–º JSONL –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é","t":time.time()-start,"job_id":res["job_id"]}
    time.sleep(0.2); yield {"event":"done","result":res,"t":time.time()-start}
